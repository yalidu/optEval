{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import StrMethodFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from alpha_rank import alpha_rank\n",
    "from functools import partial\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "from sampling_test import _kendall_partial as kendall_partial\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Name of the folder you want to save graphs too\n",
    "exps_name = \"Graphs\"\n",
    "\n",
    "# Only load the runs with this experiment label\n",
    "labels = []\n",
    "\n",
    "# Directory where the runs are saved\n",
    "direc_to_look = \"...\"\n",
    "\n",
    "# Only look in these folders in that directory\n",
    "folders_to_look = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exps_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folders_to_look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "direc_to_look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "direc_to_save = \"\" # Where you want to save the stuff\n",
    "orignal_direc = \"{}/{}\".format(direc_to_save, exps_name)\n",
    "os.makedirs(orignal_direc, exist_ok=True)\n",
    "os.makedirs(orignal_direc+\"/median\", exist_ok=True)\n",
    "os.makedirs(orignal_direc+\"/mean\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data on these parameters\n",
    "params = [\n",
    "            \"sampler\",\n",
    "            \"acquisition\",\n",
    "            \"delta\",\n",
    "            \"starting_var\",\n",
    "            \"noise_var\",\n",
    "            ]\n",
    "\n",
    "# Seperate graphs for these\n",
    "facets = [\n",
    "    \"env\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_func(exp_info):\n",
    "    if exp_info[\"label\"] not in labels:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "keys_no_repeat = set()\n",
    "all_faces = set()\n",
    "\n",
    "files_to_check = glob.glob(\"{}/{}/*.pkl\".format(direc_to_look, \"*\"))\n",
    "print(\"TOTAL FILES TO CHECK:\", len(files_to_check))\n",
    "for i, d in enumerate(files_to_check):\n",
    "    skip_entry = not any([fs in d for fs in folders_to_look])\n",
    "    if skip_entry:\n",
    "        continue\n",
    "    print(i,end=\",\")\n",
    "    with open(d, \"rb\") as f:\n",
    "        data_dict = pickle.load(f)\n",
    "        exp_info = data_dict[\"exp_info\"]\n",
    "        if not filter_func(exp_info):\n",
    "            continue\n",
    "        params_str = \"__\".join([str(exp_info.get(s, \"N/A\")) for s in params])\n",
    "        keys_no_repeat.add(params_str)\n",
    "        params_str += \"#{}_{}_{}\".format(exp_info[\"repeats\"], labels.index(exp_info[\"label\"]), [f in d for f in folders_to_look].index(True))\n",
    "        faces_str = \"__\".join([str(exp_info.get(s, \"N/A\")) for s in facets])\n",
    "        all_faces.add(faces_str)\n",
    "        full_str = \"{}++{}\".format(faces_str, params_str)\n",
    "        runs = all_data.get(full_str, [])\n",
    "        runs.append(data_dict)\n",
    "        all_data[full_str] = runs\n",
    "        \n",
    "print(\"\\nDONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to filter what runs are graphed (from amongst the runs loaded)\n",
    "def filter_func2(exp_info):\n",
    "    \n",
    "    # For instance if we didn't want to graph the lines for ResponseGraphUCB:\n",
    "    #     if exp_info[\"sampler\"] == \"freq2\":\n",
    "    #         return False\n",
    "\n",
    "    # Return True if you want the line\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data and do some more filtering if you want\n",
    "data = {}\n",
    "faces = set()\n",
    "runs_per = {}\n",
    "\n",
    "for k in all_data.keys():\n",
    "    exp_info = all_data[k][0][\"exp_info\"]\n",
    "    if not filter_func2(exp_info):\n",
    "        continue\n",
    "    faces_str = \"__\".join([str(exp_info.get(s, \"N/A\")) for s in facets])\n",
    "    faces.add(faces_str)\n",
    "    data[k] = all_data[k]\n",
    "    no_r_key = k.split(\"#\")[0]\n",
    "    val = runs_per.get(no_r_key, 0)\n",
    "    runs_per[no_r_key] = val + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Keys:\",keys_no_repeat,\"\\n\")\n",
    "print(\"Keys Size:\",len(keys_no_repeat),\"\\n\")\n",
    "print(\"Length:\",len(data.values()),\"\\n\")\n",
    "print(\"Faces:\", faces, \"\\n\")\n",
    "data_keys = list(data.keys())\n",
    "\n",
    "print(\"Faces: [{}]\".format(len(faces)))\n",
    "for face in faces:\n",
    "    print(face)\n",
    "    \n",
    "print(\"\\nRepeats per:\")\n",
    "for k in sorted(runs_per.keys()):\n",
    "    print(\"{}: [{}]\".format(k, runs_per[k]))\n",
    "\n",
    "print(\"\\n------\\n\")\n",
    "for k in data.keys():\n",
    "    a = data[k]\n",
    "    print(k, \":\", len(a))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get data common to all the runs\n",
    "run_data = data[data_keys[0]][0]\n",
    "\n",
    "exp = run_data[\"exp_info\"]\n",
    "t_max = exp[\"t_max\"]\n",
    "num_pops = run_data[\"env_info\"][\"num_pops\"]\n",
    "num_players = run_data[\"env_info\"][\"num_players\"]\n",
    "num_strats = run_data[\"env_info\"][\"num_strats\"]\n",
    "\n",
    "true_payoff = run_data[\"env_info\"][\"true_payoffs\"]\n",
    "alpha_rank_partial = partial(alpha_rank, alpha=exp[\"alpha\"], mutation=exp[\"alpha_mutation\"], use_inf_alpha=exp[\"inf_alpha\"], inf_alpha_eps=exp[\"inf_alpha_eps\"])\n",
    "true_alpha_rank = alpha_rank_partial(true_payoff)\n",
    "alpha_rank_strats = true_alpha_rank.shape[0]\n",
    "\n",
    "# For every run we might have a seperate environment, fill in the data about the true alpha ranking\n",
    "for key in data_keys:\n",
    "    for run in data[key]:\n",
    "        run_payoff = run[\"env_info\"][\"true_payoffs\"]\n",
    "        true_alpha_rank = alpha_rank_partial(run_payoff)\n",
    "        run[\"env_info\"][\"true_alpha_rank\"] = true_alpha_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If ResponseGraphUCB has stopped sampling, duplicate the entries at the end to match up with t_max\n",
    "for key in data.keys():\n",
    "    for runs in data[key]:\n",
    "        if len(runs[\"mean_alpha_rankings\"]) < t_max:\n",
    "            old = runs[\"mean_alpha_rankings\"]\n",
    "            new_data = old + [old[-1] for _ in range(t_max - len(old))]\n",
    "            runs[\"mean_alpha_rankings\"] = new_data\n",
    "        if len(runs[\"alpha_rankings_more\"]) < 100:\n",
    "            print(key,end=\",\")\n",
    "            old = runs[\"alpha_rankings_more\"]\n",
    "            new_data = old + [old[-1] for _ in range(100 - len(old))]\n",
    "            runs[\"alpha_rankings_more\"] = new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_repeats = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keys_to_plot = list(runs_per.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def smooth_ma(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    s=np.concatenate([np.array([y[0] for _ in range(box_pts//2)]), y, np.array([y[-1] for _ in range(box_pts//2)])])\n",
    "    y_smooth = np.convolve(s, box, mode='valid')\n",
    "    return y_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the names of the runs into something nice/readable\n",
    "def get_nice_name(k):\n",
    "    if \"++bayesian__ndd\" in k:\n",
    "        return r\"$\\alpha$IG (NSB)\"\n",
    "    if \"++bayesian__entropy\" in k:\n",
    "        return r\"$\\alpha$IG (Bins)\"\n",
    "    if \"++bayesian__l1\" in k:\n",
    "        return r\"$\\alpha$Wass\"\n",
    "    if \"++freq2\" in k:\n",
    "        return \"RG-UCB\"\n",
    "    if \"++random\" in k:\n",
    "        return \"Uniform\"\n",
    "    if \"++payoff\" in k:\n",
    "        return \"Payoff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Function to graph data with the style used in the paper\n",
    "def graph(  keys,\n",
    "            processer, \n",
    "            aggregate=lambda x: np.mean(x, axis=0), \n",
    "            stat=lambda x: np.mean(x, axis=0),\n",
    "            upper=lambda x: np.mean(x, axis=0) + np.std(x, axis=0),\n",
    "            lower=lambda x: np.mean(x, axis=0) - np.std(x, axis=0),\n",
    "            smooth=True,\n",
    "            smooth_window=101,\n",
    "            algo_colours=True):\n",
    "\n",
    "    keys_r_data = {}\n",
    "    \n",
    "    keys_data = []\n",
    "    keys_upper = []\n",
    "    keys_lower = []\n",
    "    keys_name = []\n",
    "    keys_num = []\n",
    "    \n",
    "    print(\"Getting quantities.\")\n",
    "    for key in keys:\n",
    "        print(key, end=\", \")\n",
    "        key_data = data[key] # List of dictionarties\n",
    "        processed_data = []\n",
    "        for run in key_data:\n",
    "            points = processer(run)\n",
    "            processed_data.append(points)\n",
    "        processed_data = np.array(processed_data)\n",
    "        aggregated_data = aggregate(processed_data) # For each repeat we have the data we want to graph\n",
    "        \n",
    "        no_r_key = key.split(\"#\")[0]\n",
    "        if no_r_key not in keys_r_data:\n",
    "            keys_r_data[no_r_key] = [aggregated_data]\n",
    "        else:\n",
    "            keys_r_data[no_r_key].append(aggregated_data)\n",
    "        \n",
    "    print(\"Computing stats\")\n",
    "    for key in keys_r_data.keys():\n",
    "        concat_data = np.stack(keys_r_data[key], axis=0)[:max_repeats]\n",
    "        \n",
    "        s_data = stat(concat_data)\n",
    "        u_data = upper(concat_data)\n",
    "        l_data = lower(concat_data)\n",
    "\n",
    "        keys_data.append(s_data)\n",
    "        keys_upper.append(u_data)\n",
    "        keys_lower.append(l_data)\n",
    "        keys_name.append(key)\n",
    "        keys_num.append(len(concat_data))\n",
    "    \n",
    "    colour_scheme = {\n",
    "        \"bayesian__l1\": \"#d8345f\",\n",
    "        \"bayesian__ndd\": \"#6886c5\",\n",
    "        \"bayesian__entropy\": \"#b19cd9\",\n",
    "        \"freq2\": \"#649d66\",\n",
    "        \"random\": \"#656569\",\n",
    "        \"payoff\": \"#ec823a\",\n",
    "    }\n",
    "\n",
    "    print(\"Plotting\")\n",
    "    plt.figure(figsize=(12,10))\n",
    "    for name, x, xu, xl, n in zip(keys_name, keys_data, keys_upper, keys_lower, keys_num):\n",
    "        xs = range(len(x))\n",
    "        smoothed_x = smooth_ma(x, smooth_window) if smooth else x\n",
    "        color_to_use = None\n",
    "        for cks in colour_scheme.keys():\n",
    "            if cks in name:\n",
    "                color_to_use = colour_scheme[cks]\n",
    "        if algo_colours:\n",
    "            label_name = get_nice_name(name)\n",
    "            plt.plot(xs, smoothed_x, label=\"{} [{}]\".format(label_name, n), linewidth=3, alpha=0.9, color=color_to_use)\n",
    "            plt.fill_between(xs, xl if not smooth else smooth_ma(xl, smooth_window), xu if not smooth else smooth_ma(xu, smooth_window), alpha=0.3, color=color_to_use)\n",
    "        else:\n",
    "            plt.plot(xs, smoothed_x, label=\"{} [{}]\".format(name, n), linewidth=3, alpha=0.9)\n",
    "            plt.fill_between(xs, xl if not smooth else smooth_ma(xl, smooth_window), xu if not smooth else smooth_ma(xu, smooth_window), alpha=0.3)\n",
    "    if algo_colours:\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        name_order = [r\"$\\alpha$IG (Bins)\", r\"$\\alpha$IG (NSB)\", r\"$\\alpha$Wass\", \"RG-UCB\" ,\"Payoff\", \"Uniform\"]\n",
    "        if len(labels) < len(name_order):\n",
    "            # We're not graphing Uniform, leave it out of the name_order\n",
    "            name_order = name_order[:-1]\n",
    "        order = [[i for i,l in enumerate(labels) if l.startswith(n)][0] for n in name_order]\n",
    "        leg = plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order], bbox_to_anchor=(1.01, 1), loc=2, fontsize=36, handlelength=1)\n",
    "    else:\n",
    "        leg = plt.legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\n",
    "    for legobj in leg.legendHandles:\n",
    "        legobj.set_linewidth(4 if not algo_colours else 10)\n",
    "        \n",
    "    plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SAVING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Median func defaults\n",
    "med_f = lambda x: np.median(x, axis=0)\n",
    "med_l = lambda x: np.min(x, axis=0)\n",
    "med_u = lambda x: np.max(x, axis=0)\n",
    "median_graph = partial(graph, stat=med_f, lower=med_l, upper=med_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "direc = \"{}/median\".format(orignal_direc)\n",
    "def save_plot(name, face, m=None):\n",
    "    os.makedirs(direc+\"/{}\".format(face), exist_ok=True)\n",
    "    if m is None:\n",
    "        plt.savefig(\"{}/{}/{}.png\".format(direc, face, name), bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(\"{}/{}/{}__{}.png\".format(direc, face, name, m), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "title_to_use = \"3 Good, 5 Bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "use_nice_name = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for face in faces:\n",
    "    print(\"Face: {}\".format(face))\n",
    "    if \"random__\" in face:\n",
    "        continue\n",
    "    keys = set([k for k in data.keys() if k.startswith(\"{}++\".format(face)) and k.split(\"#\")[0] in keys_to_plot and \"random\" not in k])\n",
    "    single_env = True if len(data[list(keys)[0]]) == 1 else False\n",
    "    print(\"Single env:\", single_env)\n",
    "    \n",
    "    # Frequentist regret = 1- P(Correct alpha_rank)\n",
    "    for cc in [0.01]:\n",
    "        def p_alpha_correct(d):\n",
    "            return [1 - np.mean([np.abs(np.around(a, 3)-np.around(d[\"env_info\"][\"true_alpha_rank\"], 3)).sum()<cc for a in x]) for x in d[\"alpha_rankings_more\"]]\n",
    "        median_graph(keys, p_alpha_correct, smooth=False, smooth_window=101,algo_colours=use_nice_name,\n",
    "                        stat = lambda x: np.mean(x, axis=0),\n",
    "                        lower = lambda x: np.mean(x, axis=0) - np.std(x, axis=0)/np.sqrt(x.shape[0]),\n",
    "                        upper = lambda x: np.mean(x, axis=0) + np.std(x, axis=0)/np.sqrt(x.shape[0]),\n",
    "                        use_parallel=True)\n",
    "\n",
    "        plt.xlabel(\"Samples\", fontsize=40)\n",
    "        plt.ylabel(r\"$1 - P(r_{GT})$\", fontsize=40)\n",
    "        plt.ylim(-0.05,1.05)\n",
    "        plt.xticks([0,20,40,60,80,100], [\"{:,.0f}\".format(x * t_max) for x in [0,0.2,0.4,0.6,0.8,1.0]], fontsize=34)\n",
    "        plt.yticks(fontsize=34)\n",
    "        plt.title(title_to_use, fontsize=40)\n",
    "        plt.legend('',frameon=False)\n",
    "        if SAVING:\n",
    "            save_plot(\"freq_regret_{}\".format(cc), face)\n",
    "        plt.close()\n",
    "        print(\"Plotted freq regret,\",cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for face in faces:\n",
    "    print(\"Face: {}\".format(face))\n",
    "    if \"random__\" in face:\n",
    "        continue\n",
    "    keys = set([k for k in data.keys() if k.startswith(\"{}++\".format(face)) and k.split(\"#\")[0] in keys_to_plot  and \"random\" not in k])\n",
    "    single_env = True if len(data[list(keys)[0]]) == 1 else False\n",
    "    print(\"Single env:\", single_env)\n",
    "        \n",
    "    # Bayesian regret = P(Most probable alpha_rank)\n",
    "    def prob_ps(d):\n",
    "        pp = []\n",
    "        for x in d[\"alpha_rankings_more\"]:\n",
    "            unique_phis, counts = np.unique(np.around(x, decimals=3), return_counts=True, axis=0)\n",
    "            argmax_entry = np.argmax(counts)\n",
    "            p_phi = unique_phis[argmax_entry]\n",
    "            p_phi_prob = counts[argmax_entry] / sum(counts)\n",
    "            pp.append(1 - p_phi_prob)\n",
    "        return pp\n",
    "    median_graph(keys, prob_ps,smooth=False, smooth_window=101,algo_colours=use_nice_name,\n",
    "                        stat = lambda x: np.mean(x, axis=0),\n",
    "                        lower = lambda x: np.mean(x, axis=0) - np.std(x, axis=0)/np.sqrt(x.shape[0]),\n",
    "                        upper = lambda x: np.mean(x, axis=0) + np.std(x, axis=0)/np.sqrt(x.shape[0]))\n",
    "\n",
    "    plt.xlabel(\"Samples\", fontsize=40)\n",
    "    plt.ylabel(r\"$1 - P(r_{*})$\", fontsize=40)\n",
    "    plt.ylim(-0.05,1.05)\n",
    "    plt.xticks([0,20,40,60,80,100], [\"{:,.0f}\".format(x * t_max) for x in [0,0.2,0.4,0.6,0.8,1.0]], fontsize=34)\n",
    "    plt.yticks(fontsize=34)\n",
    "    plt.title(title_to_use, fontsize=40)\n",
    "    plt.legend('',frameon=False)\n",
    "    if SAVING:\n",
    "        save_plot(\"bayesian_regret\", face)\n",
    "    plt.close()\n",
    "    print(\"Plotted bayesian_regret.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for face in faces:\n",
    "    print(\"Face: {}\".format(face))\n",
    "    keys = set([k for k in data.keys() if k.startswith(\"{}++\".format(face)) and k.split(\"#\")[0] in keys_to_plot])\n",
    "    single_env = True if len(data[list(keys)[0]]) == 1 else False\n",
    "    print(\"Single env:\", single_env)\n",
    "    \n",
    "    # Number of seeds correct\n",
    "    m_alpha_rank = lambda d: [x[0] for x in d[\"mean_alpha_rankings\"]]\n",
    "    alpha_correct = lambda d: [1- np.linalg.norm(a-d[\"env_info\"][\"true_alpha_rank\"], ord=1)<0.01 for a in m_alpha_rank(d)]\n",
    "    graph(keys, alpha_correct,\n",
    "            stat = lambda x: np.mean(x, axis=0),\n",
    "            lower = lambda x: np.mean(x, axis=0) - np.std(x, axis=0)/np.sqrt(x.shape[0]),\n",
    "            upper = lambda x: np.mean(x, axis=0) + np.std(x, axis=0)/np.sqrt(x.shape[0]),\n",
    "            smooth=True,\n",
    "            smooth_window=401 if t_max >= 20*1000 else 201,\n",
    "            algo_colours=use_nice_name)\n",
    "    plt.xlabel(\"Samples\", fontsize=40)\n",
    "    plt.xticks(fontsize=34)\n",
    "    plt.ylabel(r\"$1 - P(f(\\bar{M}) = r_{gt})$\", fontsize=40)\n",
    "    plt.yticks(fontsize=34)\n",
    "    plt.ylim(-0.05,1.05)\n",
    "    plt.title(title_to_use, fontsize=40)\n",
    "    if SAVING:\n",
    "        save_plot(\"mean_correct\", face)\n",
    "    plt.close()\n",
    "    print(\"Plotted % correct alpha ranking.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
